{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c573222-664a-424d-ae6d-4d48067c1da0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f26614-410d-4cbd-907c-2df87c4a61b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A complete implementation and training of a CIFAR10 classifier.\n",
    "\n",
    "The prompt is to create another LearningRateScheduler.\n",
    "\n",
    "\"\"\"\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import MiniCNN\n",
    "from scheduler import CustomLRScheduler\n",
    "from config import CONFIG\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048eb292-c03a-47d1-80ac-460a9d35613f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cifar10_data() -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Get the CIFAR10 data from torchvision.\n",
    "\n",
    "    Arguments:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        train_loader (DataLoader): The training data loader.\n",
    "        test_loader (DataLoader): The test data loader.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get the training data:\n",
    "    train_data = CIFAR10(\n",
    "        root=\"data/cifar10\", train=True, download=True, transform=CONFIG.transforms\n",
    "    )\n",
    "    # Create a data loader for the training data:\n",
    "    train_loader = DataLoader(train_data, batch_size=CONFIG.batch_size, shuffle=True)\n",
    "    # Get the test data:\n",
    "    test_data = CIFAR10(\n",
    "        root=\"data/cifar10\", train=False, download=True, transform=CONFIG.transforms\n",
    "    )\n",
    "    # Create a data loader for the test data:\n",
    "    test_loader = DataLoader(test_data, batch_size=CONFIG.batch_size, shuffle=True)\n",
    "    # Return the data loaders:\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    num_epochs: int,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.Module,\n",
    "    learning_rate_scheduler: torch.optim.lr_scheduler._LRScheduler,\n",
    "    device: torch.device = device,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Train a model on the data.\n",
    "\n",
    "    Arguments:\n",
    "        model (torch.nn.Module): The model to train.\n",
    "        train_loader (DataLoader): The training data loader.\n",
    "        test_loader (DataLoader): The test data loader.\n",
    "        num_epochs (int): The number of epochs to train for.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer to use.\n",
    "        criterion (torch.nn.Module): The loss function to use.\n",
    "        learning_rate_scheduler (torch.optim.lr_scheduler._LRScheduler): The\n",
    "            learning rate scheduler to use.\n",
    "        device (torch.device): The device to use for training.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    # Move the model to the device:\n",
    "    model.to(device)\n",
    "    # Loop over the epochs:\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode:\n",
    "        model.train()\n",
    "        # Loop over the training data:\n",
    "        for x, y in tqdm(train_loader):\n",
    "            # Move the data to the device:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # Zero the gradients:\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass:\n",
    "            y_hat = model(x)\n",
    "            # Compute the loss:\n",
    "            loss = criterion(y_hat, y)\n",
    "            # Backward pass:\n",
    "            loss.backward()\n",
    "            # Update the parameters:\n",
    "            optimizer.step()\n",
    "            # Update the learning rate:\n",
    "            learning_rate_scheduler.step()\n",
    "        # Set the model to evaluation mode:\n",
    "        model.eval()\n",
    "        # Compute the accuracy on the test data:\n",
    "        accuracy = compute_accuracy(model, test_loader, device)\n",
    "        # Print the results:\n",
    "        print(f\"Epoch {epoch + 1} | Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "def compute_accuracy(\n",
    "    model: torch.nn.Module, data_loader: DataLoader, device: torch.device = device\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute the accuracy of a model on some data.\n",
    "\n",
    "    Arguments:\n",
    "        model (torch.nn.Module): The model to compute the accuracy of.\n",
    "        data_loader (DataLoader): The data loader to use.\n",
    "        device (torch.device): The device to use for training.\n",
    "\n",
    "    Returns:\n",
    "        accuracy (float): The accuracy of the model on the data.\n",
    "\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode:\n",
    "    model.eval()\n",
    "    # Initialize the number of correct predictions:\n",
    "    num_correct = 0\n",
    "    # Loop over the data:\n",
    "    for x, y in data_loader:\n",
    "        # Move the data to the device:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # Forward pass:\n",
    "        y_hat = model(x)\n",
    "        # Compute the predictions:\n",
    "        predictions = torch.argmax(y_hat, dim=1)\n",
    "        # Update the number of correct predictions:\n",
    "        num_correct += torch.sum(predictions == y).item()\n",
    "    # Compute the accuracy:\n",
    "    accuracy = num_correct / len(data_loader.dataset)\n",
    "    # Return the accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94ef68-7649-4617-a90e-96ae8687411a",
   "metadata": {},
   "source": [
    "## Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7c115ec-a299-406f-94cf-f09365539782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Create the data loaders:\n",
    "train_loader, test_loader = get_cifar10_data()\n",
    "# Create the model:\n",
    "model = MiniCNN(num_channels=3)\n",
    "# Create the optimizer:\n",
    "optimizer = CONFIG.optimizer_factory(model)\n",
    "# Create the loss function:\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f9ab78-f3e9-407b-ace9-aa0cd85b18dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 782/782 [00:09<00:00, 79.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Test Accuracy: 0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 782/782 [00:10<00:00, 77.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Test Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Create the learning rate scheduler:\n",
    "learning_rate_scheduler = CustomLRScheduler(optimizer, **CONFIG.lrs_kwargs)\n",
    "# Train the model:\n",
    "train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    num_epochs=CONFIG.num_epochs,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    learning_rate_scheduler=learning_rate_scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca07abc-703b-4648-bc15-d5fb9ce56411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi-env",
   "language": "python",
   "name": "mi-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
